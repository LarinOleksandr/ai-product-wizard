services:
  embeddings:
    image: ai-embeddings-dev                 # use the manually built image
    container_name: ai-embeddings-dev
    ports:
      - "8001:8001"
    restart: unless-stopped

  orchestrator:
    build:
      context: ../../ai/orchestrator
    container_name: ai-orchestrator-dev
    ports:
      - "8002:8002"
    depends_on:
      - embeddings
    environment:
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
    volumes:
      - ../../knowledge-base:/knowledge-base:ro
    restart: unless-stopped

  flowise:
    image: flowiseai/flowise:1.6.0
    container_name: flowise
    command: ["flowise", "start"]
    ports:
      - "3001:3000"
    volumes:
      - flowise-data:/root/.flowise
    restart: unless-stopped

volumes:
  flowise-data:
